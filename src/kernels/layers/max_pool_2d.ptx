//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36037853
// Cuda compilation tools, release 12.9, V12.9.86
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_52
.address_size 64

	// .globl	forward

.visible .entry forward(
	.param .u64 forward_param_0,
	.param .u64 forward_param_1,
	.param .u64 forward_param_2,
	.param .u32 forward_param_3,
	.param .u32 forward_param_4,
	.param .u32 forward_param_5,
	.param .u32 forward_param_6,
	.param .u32 forward_param_7,
	.param .u32 forward_param_8,
	.param .u32 forward_param_9
)
{
	.reg .pred 	%p<37>;
	.reg .f32 	%f<42>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<14>;


	ld.param.u64 	%rd6, [forward_param_0];
	ld.param.u64 	%rd4, [forward_param_1];
	ld.param.u64 	%rd5, [forward_param_2];
	ld.param.u32 	%r51, [forward_param_3];
	ld.param.u32 	%r46, [forward_param_4];
	ld.param.u32 	%r47, [forward_param_5];
	ld.param.u32 	%r48, [forward_param_6];
	ld.param.u32 	%r49, [forward_param_7];
	ld.param.u32 	%r50, [forward_param_8];
	ld.param.u32 	%r52, [forward_param_9];
	cvta.to.global.u64 	%rd1, %rd6;
	mov.u32 	%r53, %ntid.x;
	mov.u32 	%r54, %ctaid.x;
	mov.u32 	%r55, %tid.x;
	mad.lo.s32 	%r1, %r54, %r53, %r55;
	mul.lo.s32 	%r2, %r52, %r50;
	mul.lo.s32 	%r56, %r2, %r51;
	setp.ge.s32 	%p1, %r1, %r56;
	@%p1 bra 	$L__BB0_25;

	rem.u32 	%r58, %r1, %r50;
	mul.lo.s32 	%r3, %r58, %r49;
	setp.eq.s32 	%p2, %r48, 0;
	mov.u32 	%r79, -1;
	mov.f32 	%f32, 0fFF800000;
	@%p2 bra 	$L__BB0_24;

	div.u32 	%r61, %r1, %r2;
	mul.lo.s32 	%r4, %r61, %r47;
	add.s32 	%r5, %r48, -1;
	mov.u32 	%r79, -1;
	and.b32  	%r6, %r48, 3;
	sub.s32 	%r7, %r48, %r6;
	mul.lo.s32 	%r62, %r61, %r2;
	sub.s32 	%r63, %r1, %r62;
	div.u32 	%r64, %r63, %r50;
	mul.lo.s32 	%r8, %r64, %r49;
	mov.f32 	%f32, 0fFF800000;
	mov.u32 	%r59, 0;
	mov.u32 	%r74, %r59;

$L__BB0_3:
	add.s32 	%r11, %r74, %r8;
	add.s32 	%r67, %r11, %r4;
	mul.lo.s32 	%r12, %r67, %r46;
	setp.lt.u32 	%p3, %r5, 3;
	mov.u32 	%r84, %r59;
	@%p3 bra 	$L__BB0_14;

	mov.u32 	%r84, 0;
	mov.u32 	%r78, %r7;

$L__BB0_5:
	add.s32 	%r16, %r84, %r3;
	setp.ge.u32 	%p4, %r16, %r46;
	setp.ge.u32 	%p5, %r11, %r47;
	add.s32 	%r17, %r16, %r12;
	mul.wide.s32 	%rd7, %r17, 4;
	add.s64 	%rd2, %rd1, %rd7;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB0_7;

	ld.global.f32 	%f23, [%rd2];
	setp.gt.f32 	%p7, %f23, %f32;
	selp.f32 	%f32, %f23, %f32, %p7;
	selp.b32 	%r79, %r17, %r79, %p7;

$L__BB0_7:
	add.s32 	%r20, %r16, 1;
	setp.ge.u32 	%p8, %r20, %r46;
	or.pred  	%p10, %p5, %p8;
	@%p10 bra 	$L__BB0_9;

	add.s32 	%r69, %r20, %r12;
	ld.global.f32 	%f24, [%rd2+4];
	setp.gt.f32 	%p11, %f24, %f32;
	selp.f32 	%f32, %f24, %f32, %p11;
	selp.b32 	%r79, %r69, %r79, %p11;

$L__BB0_9:
	add.s32 	%r23, %r16, 2;
	setp.ge.u32 	%p12, %r23, %r46;
	or.pred  	%p14, %p5, %p12;
	@%p14 bra 	$L__BB0_11;

	add.s32 	%r70, %r23, %r12;
	ld.global.f32 	%f25, [%rd2+8];
	setp.gt.f32 	%p15, %f25, %f32;
	selp.f32 	%f32, %f25, %f32, %p15;
	selp.b32 	%r79, %r70, %r79, %p15;

$L__BB0_11:
	add.s32 	%r26, %r16, 3;
	setp.ge.u32 	%p16, %r26, %r46;
	or.pred  	%p18, %p5, %p16;
	@%p18 bra 	$L__BB0_13;

	add.s32 	%r71, %r26, %r12;
	ld.global.f32 	%f26, [%rd2+12];
	setp.gt.f32 	%p19, %f26, %f32;
	selp.f32 	%f32, %f26, %f32, %p19;
	selp.b32 	%r79, %r71, %r79, %p19;

$L__BB0_13:
	add.s32 	%r84, %r84, 4;
	add.s32 	%r78, %r78, -4;
	setp.ne.s32 	%p20, %r78, 0;
	@%p20 bra 	$L__BB0_5;

$L__BB0_14:
	setp.eq.s32 	%p21, %r6, 0;
	@%p21 bra 	$L__BB0_23;

	setp.ge.u32 	%p22, %r11, %r47;
	add.s32 	%r34, %r84, %r3;
	setp.ge.u32 	%p23, %r34, %r46;
	add.s32 	%r35, %r34, %r12;
	mul.wide.s32 	%rd8, %r35, 4;
	add.s64 	%rd3, %rd1, %rd8;
	or.pred  	%p24, %p22, %p23;
	@%p24 bra 	$L__BB0_17;

	ld.global.f32 	%f27, [%rd3];
	setp.gt.f32 	%p25, %f27, %f32;
	selp.f32 	%f32, %f27, %f32, %p25;
	selp.b32 	%r79, %r35, %r79, %p25;

$L__BB0_17:
	setp.eq.s32 	%p26, %r6, 1;
	@%p26 bra 	$L__BB0_23;

	add.s32 	%r38, %r34, 1;
	setp.ge.u32 	%p28, %r38, %r46;
	or.pred  	%p29, %p22, %p28;
	@%p29 bra 	$L__BB0_20;

	add.s32 	%r72, %r38, %r12;
	ld.global.f32 	%f28, [%rd3+4];
	setp.gt.f32 	%p30, %f28, %f32;
	selp.f32 	%f32, %f28, %f32, %p30;
	selp.b32 	%r79, %r72, %r79, %p30;

$L__BB0_20:
	setp.eq.s32 	%p31, %r6, 2;
	@%p31 bra 	$L__BB0_23;

	add.s32 	%r41, %r34, 2;
	setp.ge.u32 	%p33, %r41, %r46;
	or.pred  	%p34, %p22, %p33;
	@%p34 bra 	$L__BB0_23;

	add.s32 	%r73, %r41, %r12;
	ld.global.f32 	%f29, [%rd3+8];
	setp.gt.f32 	%p35, %f29, %f32;
	selp.f32 	%f32, %f29, %f32, %p35;
	selp.b32 	%r79, %r73, %r79, %p35;

$L__BB0_23:
	add.s32 	%r74, %r74, 1;
	setp.lt.u32 	%p36, %r74, %r48;
	@%p36 bra 	$L__BB0_3;

$L__BB0_24:
	cvta.to.global.u64 	%rd9, %rd4;
	mul.wide.s32 	%rd10, %r1, 4;
	add.s64 	%rd11, %rd9, %rd10;
	st.global.f32 	[%rd11], %f32;
	cvta.to.global.u64 	%rd12, %rd5;
	add.s64 	%rd13, %rd12, %rd10;
	st.global.u32 	[%rd13], %r79;

$L__BB0_25:
	ret;

}
	// .globl	reset_gradient
.visible .entry reset_gradient(
	.param .u64 reset_gradient_param_0,
	.param .u32 reset_gradient_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [reset_gradient_param_0];
	ld.param.u32 	%r2, [reset_gradient_param_1];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.u32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB1_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mul.wide.s32 	%rd3, %r1, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.u32 	%r6, 0;
	st.global.u32 	[%rd4], %r6;

$L__BB1_2:
	ret;

}
	// .globl	backward
.visible .entry backward(
	.param .u64 backward_param_0,
	.param .u64 backward_param_1,
	.param .u64 backward_param_2,
	.param .u32 backward_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<14>;


	ld.param.u64 	%rd2, [backward_param_0];
	ld.param.u64 	%rd3, [backward_param_1];
	ld.param.u64 	%rd4, [backward_param_2];
	ld.param.u32 	%r3, [backward_param_3];
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r5, %r4, %r6;
	setp.ge.u32 	%p1, %r1, %r3;
	@%p1 bra 	$L__BB2_3;

	cvta.to.global.u64 	%rd5, %rd4;
	cvt.s64.s32 	%rd1, %r1;
	mul.wide.s32 	%rd6, %r1, 4;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.u32 	%r2, [%rd7];
	setp.eq.s32 	%p2, %r2, -1;
	@%p2 bra 	$L__BB2_3;

	cvta.to.global.u64 	%rd8, %rd3;
	mul.wide.s32 	%rd9, %r2, 4;
	add.s64 	%rd10, %rd8, %rd9;
	cvta.to.global.u64 	%rd11, %rd2;
	shl.b64 	%rd12, %rd1, 2;
	add.s64 	%rd13, %rd11, %rd12;
	ld.global.f32 	%f1, [%rd13];
	atom.global.add.f32 	%f2, [%rd10], %f1;

$L__BB2_3:
	ret;

}

