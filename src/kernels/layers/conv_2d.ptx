//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36037853
// Cuda compilation tools, release 12.9, V12.9.86
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_52
.address_size 64

	// .globl	forward

.visible .entry forward(
	.param .u64 forward_param_0,
	.param .u64 forward_param_1,
	.param .u64 forward_param_2,
	.param .u64 forward_param_3,
	.param .u32 forward_param_4,
	.param .u32 forward_param_5,
	.param .u32 forward_param_6,
	.param .u32 forward_param_7,
	.param .u32 forward_param_8,
	.param .u32 forward_param_9,
	.param .u32 forward_param_10,
	.param .u32 forward_param_11
)
{
	.reg .pred 	%p<13>;
	.reg .f32 	%f<43>;
	.reg .b32 	%r<66>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd5, [forward_param_0];
	ld.param.u64 	%rd3, [forward_param_1];
	ld.param.u64 	%rd6, [forward_param_2];
	ld.param.u64 	%rd4, [forward_param_3];
	ld.param.u32 	%r20, [forward_param_4];
	ld.param.u32 	%r21, [forward_param_5];
	ld.param.u32 	%r22, [forward_param_6];
	ld.param.u32 	%r23, [forward_param_7];
	ld.param.u32 	%r24, [forward_param_8];
	ld.param.u32 	%r26, [forward_param_9];
	ld.param.u32 	%r25, [forward_param_10];
	ld.param.u32 	%r27, [forward_param_11];
	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd5;
	mov.u32 	%r28, %ntid.x;
	mov.u32 	%r29, %ctaid.x;
	mov.u32 	%r30, %tid.x;
	mad.lo.s32 	%r1, %r29, %r28, %r30;
	mul.lo.s32 	%r2, %r27, %r25;
	mul.lo.s32 	%r31, %r2, %r26;
	setp.ge.u32 	%p1, %r1, %r31;
	mov.f32 	%f41, 0f00000000;
	@%p1 bra 	$L__BB0_15;

	setp.eq.s32 	%p2, %r20, 0;
	@%p2 bra 	$L__BB0_14;

	setp.eq.s32 	%p3, %r24, 0;
	setp.eq.s32 	%p4, %r23, 0;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	$L__BB0_14;

	add.s32 	%r3, %r23, -1;
	and.b32  	%r4, %r23, 3;
	sub.s32 	%r5, %r4, %r23;
	div.u32 	%r33, %r1, %r2;
	mul.lo.s32 	%r34, %r33, %r2;
	sub.s32 	%r35, %r1, %r34;
	div.u32 	%r6, %r35, %r25;
	rem.u32 	%r7, %r1, %r25;
	mul.lo.s32 	%r8, %r33, %r20;
	mov.f32 	%f41, 0f00000000;
	mov.u32 	%r32, 0;
	mov.u32 	%r62, %r32;

$L__BB0_4:
	mad.lo.s32 	%r10, %r62, %r22, %r6;
	add.s32 	%r37, %r62, %r8;
	mul.lo.s32 	%r11, %r37, %r24;
	mov.u32 	%r63, %r32;

$L__BB0_5:
	add.s32 	%r39, %r10, %r63;
	mad.lo.s32 	%r13, %r39, %r21, %r7;
	add.s32 	%r40, %r11, %r63;
	mul.lo.s32 	%r14, %r40, %r23;
	setp.lt.u32 	%p6, %r3, 3;
	mov.u32 	%r65, 0;
	@%p6 bra 	$L__BB0_8;

	mov.u32 	%r65, 0;

$L__BB0_7:
	add.s32 	%r42, %r13, %r65;
	mul.wide.u32 	%rd7, %r42, 4;
	add.s64 	%rd8, %rd2, %rd7;
	add.s32 	%r43, %r65, %r14;
	mul.wide.u32 	%rd9, %r43, 4;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.f32 	%f16, [%rd10];
	ld.global.f32 	%f17, [%rd8];
	fma.rn.f32 	%f18, %f17, %f16, %f41;
	add.s32 	%r44, %r65, 1;
	add.s32 	%r45, %r13, %r44;
	mul.wide.u32 	%rd11, %r45, 4;
	add.s64 	%rd12, %rd2, %rd11;
	add.s32 	%r46, %r44, %r14;
	mul.wide.u32 	%rd13, %r46, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.f32 	%f19, [%rd14];
	ld.global.f32 	%f20, [%rd12];
	fma.rn.f32 	%f21, %f20, %f19, %f18;
	add.s32 	%r47, %r65, 2;
	add.s32 	%r48, %r13, %r47;
	mul.wide.u32 	%rd15, %r48, 4;
	add.s64 	%rd16, %rd2, %rd15;
	add.s32 	%r49, %r47, %r14;
	mul.wide.u32 	%rd17, %r49, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.f32 	%f22, [%rd18];
	ld.global.f32 	%f23, [%rd16];
	fma.rn.f32 	%f24, %f23, %f22, %f21;
	add.s32 	%r50, %r65, 3;
	add.s32 	%r51, %r13, %r50;
	mul.wide.u32 	%rd19, %r51, 4;
	add.s64 	%rd20, %rd2, %rd19;
	add.s32 	%r52, %r50, %r14;
	mul.wide.u32 	%rd21, %r52, 4;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.f32 	%f25, [%rd22];
	ld.global.f32 	%f26, [%rd20];
	fma.rn.f32 	%f41, %f26, %f25, %f24;
	add.s32 	%r65, %r65, 4;
	add.s32 	%r53, %r5, %r65;
	setp.ne.s32 	%p7, %r53, 0;
	@%p7 bra 	$L__BB0_7;

$L__BB0_8:
	setp.eq.s32 	%p8, %r4, 0;
	@%p8 bra 	$L__BB0_12;

	setp.eq.s32 	%p9, %r4, 1;
	add.s32 	%r54, %r13, %r65;
	mul.wide.u32 	%rd23, %r54, 4;
	add.s64 	%rd24, %rd2, %rd23;
	add.s32 	%r55, %r65, %r14;
	mul.wide.u32 	%rd25, %r55, 4;
	add.s64 	%rd26, %rd1, %rd25;
	ld.global.f32 	%f27, [%rd26];
	ld.global.f32 	%f28, [%rd24];
	fma.rn.f32 	%f41, %f28, %f27, %f41;
	@%p9 bra 	$L__BB0_12;

	add.s32 	%r56, %r65, 1;
	setp.eq.s32 	%p10, %r4, 2;
	add.s32 	%r57, %r13, %r56;
	mul.wide.u32 	%rd27, %r57, 4;
	add.s64 	%rd28, %rd2, %rd27;
	add.s32 	%r58, %r56, %r14;
	mul.wide.u32 	%rd29, %r58, 4;
	add.s64 	%rd30, %rd1, %rd29;
	ld.global.f32 	%f29, [%rd30];
	ld.global.f32 	%f30, [%rd28];
	fma.rn.f32 	%f41, %f30, %f29, %f41;
	@%p10 bra 	$L__BB0_12;

	add.s32 	%r59, %r65, 2;
	add.s32 	%r60, %r13, %r59;
	mul.wide.u32 	%rd31, %r60, 4;
	add.s64 	%rd32, %rd2, %rd31;
	add.s32 	%r61, %r59, %r14;
	mul.wide.u32 	%rd33, %r61, 4;
	add.s64 	%rd34, %rd1, %rd33;
	ld.global.f32 	%f31, [%rd34];
	ld.global.f32 	%f32, [%rd32];
	fma.rn.f32 	%f41, %f32, %f31, %f41;

$L__BB0_12:
	add.s32 	%r63, %r63, 1;
	setp.lt.u32 	%p11, %r63, %r24;
	@%p11 bra 	$L__BB0_5;

	add.s32 	%r62, %r62, 1;
	setp.lt.u32 	%p12, %r62, %r20;
	@%p12 bra 	$L__BB0_4;

$L__BB0_14:
	cvta.to.global.u64 	%rd35, %rd4;
	mul.wide.s32 	%rd36, %r1, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.f32 	%f33, [%rd37];
	add.f32 	%f34, %f41, %f33;
	cvta.to.global.u64 	%rd38, %rd3;
	add.s64 	%rd39, %rd38, %rd36;
	st.global.f32 	[%rd39], %f34;

$L__BB0_15:
	ret;

}
	// .globl	backward_input
.visible .entry backward_input(
	.param .u64 backward_input_param_0,
	.param .u64 backward_input_param_1,
	.param .u64 backward_input_param_2,
	.param .u32 backward_input_param_3,
	.param .u32 backward_input_param_4,
	.param .u32 backward_input_param_5,
	.param .u32 backward_input_param_6,
	.param .u32 backward_input_param_7,
	.param .u32 backward_input_param_8,
	.param .u32 backward_input_param_9,
	.param .u32 backward_input_param_10
)
{
	.reg .pred 	%p<47>;
	.reg .f32 	%f<55>;
	.reg .b32 	%r<96>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd4, [backward_input_param_0];
	ld.param.u64 	%rd3, [backward_input_param_1];
	ld.param.u64 	%rd5, [backward_input_param_2];
	ld.param.u32 	%r29, [backward_input_param_3];
	ld.param.u32 	%r30, [backward_input_param_4];
	ld.param.u32 	%r31, [backward_input_param_5];
	ld.param.u32 	%r32, [backward_input_param_6];
	ld.param.u32 	%r33, [backward_input_param_7];
	ld.param.u32 	%r34, [backward_input_param_8];
	ld.param.u32 	%r35, [backward_input_param_9];
	ld.param.u32 	%r36, [backward_input_param_10];
	cvta.to.global.u64 	%rd1, %rd5;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r37, %ntid.x;
	mov.u32 	%r38, %ctaid.x;
	mov.u32 	%r39, %tid.x;
	mad.lo.s32 	%r1, %r38, %r37, %r39;
	mul.lo.s32 	%r40, %r30, %r29;
	mul.lo.s32 	%r41, %r40, %r31;
	setp.ge.s32 	%p1, %r1, %r41;
	mov.f32 	%f44, 0f00000000;
	@%p1 bra 	$L__BB1_29;

	setp.eq.s32 	%p2, %r34, 0;
	@%p2 bra 	$L__BB1_28;

	setp.eq.s32 	%p3, %r33, 0;
	mov.u32 	%r42, 1;
	sub.s32 	%r43, %r42, %r32;
	rem.u32 	%r44, %r1, %r30;
	add.s32 	%r2, %r43, %r44;
	mul.lo.s32 	%r3, %r33, %r32;
	@%p3 bra 	$L__BB1_28;

	mul.lo.s32 	%r46, %r31, %r30;
	add.s32 	%r4, %r32, -1;
	and.b32  	%r5, %r32, 3;
	sub.s32 	%r6, %r5, %r32;
	div.u32 	%r47, %r1, %r46;
	mad.lo.s32 	%r7, %r47, %r3, %r32;
	mul.lo.s32 	%r8, %r33, %r29;
	mul.lo.s32 	%r48, %r47, %r46;
	sub.s32 	%r49, %r1, %r48;
	div.u32 	%r50, %r49, %r30;
	sub.s32 	%r52, %r42, %r33;
	add.s32 	%r9, %r52, %r50;
	mov.f32 	%f44, 0f00000000;
	mov.u32 	%r92, 0;

$L__BB1_4:
	setp.eq.s32 	%p4, %r32, 0;
	@%p4 bra 	$L__BB1_27;

	mad.lo.s32 	%r11, %r8, %r92, %r33;
	mul.lo.s32 	%r12, %r92, %r3;
	mov.u32 	%r53, 0;
	mov.u32 	%r93, %r53;

$L__BB1_6:
	add.s32 	%r14, %r9, %r93;
	mad.lo.s32 	%r15, %r14, %r32, %r12;
	not.b32 	%r55, %r93;
	add.s32 	%r56, %r11, %r55;
	mad.lo.s32 	%r16, %r56, %r32, %r7;
	setp.lt.u32 	%p5, %r4, 3;
	mov.u32 	%r95, %r53;
	@%p5 bra 	$L__BB1_17;

	mov.u32 	%r95, 0;

$L__BB1_8:
	add.s32 	%r18, %r2, %r95;
	setp.ge.u32 	%p6, %r18, %r35;
	or.b32  	%r58, %r18, %r14;
	setp.lt.s32 	%p7, %r58, 0;
	or.pred  	%p8, %p6, %p7;
	setp.ge.u32 	%p9, %r14, %r36;
	or.pred  	%p10, %p9, %p8;
	@%p10 bra 	$L__BB1_10;

	add.s32 	%r59, %r15, %r18;
	mul.wide.u32 	%rd6, %r59, 4;
	add.s64 	%rd7, %rd2, %rd6;
	not.b32 	%r60, %r95;
	add.s32 	%r61, %r16, %r60;
	mul.wide.u32 	%rd8, %r61, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.f32 	%f26, [%rd9];
	ld.global.f32 	%f27, [%rd7];
	fma.rn.f32 	%f44, %f27, %f26, %f44;

$L__BB1_10:
	add.s32 	%r19, %r18, 1;
	setp.ge.u32 	%p11, %r19, %r35;
	or.b32  	%r62, %r19, %r14;
	setp.lt.s32 	%p12, %r62, 0;
	or.pred  	%p13, %p11, %p12;
	or.pred  	%p15, %p9, %p13;
	@%p15 bra 	$L__BB1_12;

	add.s32 	%r63, %r15, %r19;
	mul.wide.u32 	%rd10, %r63, 4;
	add.s64 	%rd11, %rd2, %rd10;
	mov.u32 	%r64, -2;
	sub.s32 	%r65, %r64, %r95;
	add.s32 	%r66, %r16, %r65;
	mul.wide.u32 	%rd12, %r66, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f32 	%f28, [%rd13];
	ld.global.f32 	%f29, [%rd11];
	fma.rn.f32 	%f44, %f29, %f28, %f44;

$L__BB1_12:
	add.s32 	%r20, %r18, 2;
	setp.ge.u32 	%p16, %r20, %r35;
	or.b32  	%r67, %r20, %r14;
	setp.lt.s32 	%p17, %r67, 0;
	or.pred  	%p18, %p16, %p17;
	or.pred  	%p20, %p9, %p18;
	@%p20 bra 	$L__BB1_14;

	add.s32 	%r68, %r15, %r20;
	mul.wide.u32 	%rd14, %r68, 4;
	add.s64 	%rd15, %rd2, %rd14;
	mov.u32 	%r69, -3;
	sub.s32 	%r70, %r69, %r95;
	add.s32 	%r71, %r16, %r70;
	mul.wide.u32 	%rd16, %r71, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.f32 	%f30, [%rd17];
	ld.global.f32 	%f31, [%rd15];
	fma.rn.f32 	%f44, %f31, %f30, %f44;

$L__BB1_14:
	add.s32 	%r21, %r18, 3;
	setp.ge.u32 	%p21, %r21, %r35;
	or.b32  	%r72, %r21, %r14;
	setp.lt.s32 	%p22, %r72, 0;
	or.pred  	%p23, %p21, %p22;
	or.pred  	%p25, %p9, %p23;
	@%p25 bra 	$L__BB1_16;

	add.s32 	%r73, %r15, %r21;
	mul.wide.u32 	%rd18, %r73, 4;
	add.s64 	%rd19, %rd2, %rd18;
	mov.u32 	%r74, -4;
	sub.s32 	%r75, %r74, %r95;
	add.s32 	%r76, %r16, %r75;
	mul.wide.u32 	%rd20, %r76, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.f32 	%f32, [%rd21];
	ld.global.f32 	%f33, [%rd19];
	fma.rn.f32 	%f44, %f33, %f32, %f44;

$L__BB1_16:
	add.s32 	%r95, %r95, 4;
	add.s32 	%r77, %r6, %r95;
	setp.ne.s32 	%p26, %r77, 0;
	@%p26 bra 	$L__BB1_8;

$L__BB1_17:
	setp.eq.s32 	%p27, %r5, 0;
	@%p27 bra 	$L__BB1_26;

	setp.ge.u32 	%p28, %r14, %r36;
	add.s32 	%r24, %r2, %r95;
	setp.ge.u32 	%p29, %r24, %r35;
	or.b32  	%r78, %r24, %r14;
	setp.lt.s32 	%p30, %r78, 0;
	or.pred  	%p31, %p29, %p30;
	or.pred  	%p32, %p28, %p31;
	@%p32 bra 	$L__BB1_20;

	add.s32 	%r79, %r15, %r24;
	mul.wide.u32 	%rd22, %r79, 4;
	add.s64 	%rd23, %rd2, %rd22;
	not.b32 	%r80, %r95;
	add.s32 	%r81, %r16, %r80;
	mul.wide.u32 	%rd24, %r81, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.f32 	%f34, [%rd25];
	ld.global.f32 	%f35, [%rd23];
	fma.rn.f32 	%f44, %f35, %f34, %f44;

$L__BB1_20:
	setp.eq.s32 	%p33, %r5, 1;
	@%p33 bra 	$L__BB1_26;

	add.s32 	%r25, %r24, 1;
	setp.ge.u32 	%p35, %r25, %r35;
	or.b32  	%r82, %r25, %r14;
	setp.lt.s32 	%p36, %r82, 0;
	or.pred  	%p37, %p35, %p36;
	or.pred  	%p38, %p28, %p37;
	@%p38 bra 	$L__BB1_23;

	add.s32 	%r83, %r15, %r25;
	mul.wide.u32 	%rd26, %r83, 4;
	add.s64 	%rd27, %rd2, %rd26;
	mov.u32 	%r84, -2;
	sub.s32 	%r85, %r84, %r95;
	add.s32 	%r86, %r16, %r85;
	mul.wide.u32 	%rd28, %r86, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.f32 	%f36, [%rd29];
	ld.global.f32 	%f37, [%rd27];
	fma.rn.f32 	%f44, %f37, %f36, %f44;

$L__BB1_23:
	setp.eq.s32 	%p39, %r5, 2;
	@%p39 bra 	$L__BB1_26;

	add.s32 	%r26, %r24, 2;
	setp.ge.u32 	%p41, %r26, %r35;
	or.b32  	%r87, %r26, %r14;
	setp.lt.s32 	%p42, %r87, 0;
	or.pred  	%p43, %p41, %p42;
	or.pred  	%p44, %p28, %p43;
	@%p44 bra 	$L__BB1_26;

	add.s32 	%r88, %r15, %r26;
	mul.wide.u32 	%rd30, %r88, 4;
	add.s64 	%rd31, %rd2, %rd30;
	mov.u32 	%r89, -3;
	sub.s32 	%r90, %r89, %r95;
	add.s32 	%r91, %r16, %r90;
	mul.wide.u32 	%rd32, %r91, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f32 	%f38, [%rd33];
	ld.global.f32 	%f39, [%rd31];
	fma.rn.f32 	%f44, %f39, %f38, %f44;

$L__BB1_26:
	add.s32 	%r93, %r93, 1;
	setp.lt.u32 	%p45, %r93, %r33;
	@%p45 bra 	$L__BB1_6;

$L__BB1_27:
	add.s32 	%r92, %r92, 1;
	setp.lt.u32 	%p46, %r92, %r34;
	@%p46 bra 	$L__BB1_4;

$L__BB1_28:
	cvta.to.global.u64 	%rd34, %rd3;
	mul.wide.s32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	st.global.f32 	[%rd36], %f44;

$L__BB1_29:
	ret;

}
	// .globl	backward_kernel
.visible .entry backward_kernel(
	.param .u64 backward_kernel_param_0,
	.param .u64 backward_kernel_param_1,
	.param .u64 backward_kernel_param_2,
	.param .u32 backward_kernel_param_3,
	.param .u32 backward_kernel_param_4,
	.param .u32 backward_kernel_param_5,
	.param .u32 backward_kernel_param_6,
	.param .u32 backward_kernel_param_7,
	.param .u32 backward_kernel_param_8,
	.param .u32 backward_kernel_param_9,
	.param .u32 backward_kernel_param_10
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<41>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd4, [backward_kernel_param_0];
	ld.param.u64 	%rd5, [backward_kernel_param_1];
	ld.param.u64 	%rd3, [backward_kernel_param_2];
	ld.param.u32 	%r14, [backward_kernel_param_3];
	ld.param.u32 	%r15, [backward_kernel_param_4];
	ld.param.u32 	%r16, [backward_kernel_param_5];
	ld.param.u32 	%r17, [backward_kernel_param_6];
	ld.param.u32 	%r18, [backward_kernel_param_7];
	ld.param.u32 	%r21, [backward_kernel_param_8];
	ld.param.u32 	%r19, [backward_kernel_param_9];
	ld.param.u32 	%r20, [backward_kernel_param_10];
	cvta.to.global.u64 	%rd1, %rd5;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r22, %ntid.x;
	mov.u32 	%r23, %ctaid.x;
	mov.u32 	%r24, %tid.x;
	mad.lo.s32 	%r1, %r23, %r22, %r24;
	mul.lo.s32 	%r25, %r17, %r14;
	mul.lo.s32 	%r26, %r25, %r18;
	mul.lo.s32 	%r27, %r26, %r21;
	setp.ge.s32 	%p1, %r1, %r27;
	mov.f32 	%f39, 0f00000000;
	@%p1 bra 	$L__BB2_13;

	setp.eq.s32 	%p2, %r20, 0;
	@%p2 bra 	$L__BB2_12;

	setp.eq.s32 	%p3, %r19, 0;
	@%p3 bra 	$L__BB2_12;

	mul.lo.s32 	%r29, %r18, %r17;
	add.s32 	%r2, %r19, -1;
	and.b32  	%r3, %r19, 3;
	sub.s32 	%r4, %r3, %r19;
	mul.lo.s32 	%r30, %r29, %r14;
	div.u32 	%r31, %r1, %r30;
	mul.lo.s32 	%r5, %r31, %r20;
	div.u32 	%r32, %r1, %r29;
	rem.u32 	%r33, %r32, %r14;
	mul.lo.s32 	%r6, %r33, %r16;
	mov.f32 	%f39, 0f00000000;
	mov.u32 	%r28, 0;
	mov.u32 	%r58, %r28;

$L__BB2_4:
	add.s32 	%r35, %r58, %r6;
	mul.lo.s32 	%r8, %r35, %r15;
	add.s32 	%r36, %r58, %r5;
	mul.lo.s32 	%r9, %r36, %r19;
	setp.lt.u32 	%p4, %r2, 3;
	mov.u32 	%r60, %r28;
	@%p4 bra 	$L__BB2_7;

	mov.u32 	%r60, 0;

$L__BB2_6:
	add.s32 	%r38, %r60, %r8;
	mul.wide.u32 	%rd6, %r38, 4;
	add.s64 	%rd7, %rd2, %rd6;
	add.s32 	%r39, %r60, %r9;
	mul.wide.u32 	%rd8, %r39, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.f32 	%f15, [%rd9];
	ld.global.f32 	%f16, [%rd7];
	fma.rn.f32 	%f17, %f16, %f15, %f39;
	add.s32 	%r40, %r60, 1;
	add.s32 	%r41, %r40, %r8;
	mul.wide.u32 	%rd10, %r41, 4;
	add.s64 	%rd11, %rd2, %rd10;
	add.s32 	%r42, %r40, %r9;
	mul.wide.u32 	%rd12, %r42, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f32 	%f18, [%rd13];
	ld.global.f32 	%f19, [%rd11];
	fma.rn.f32 	%f20, %f19, %f18, %f17;
	add.s32 	%r43, %r60, 2;
	add.s32 	%r44, %r43, %r8;
	mul.wide.u32 	%rd14, %r44, 4;
	add.s64 	%rd15, %rd2, %rd14;
	add.s32 	%r45, %r43, %r9;
	mul.wide.u32 	%rd16, %r45, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.f32 	%f21, [%rd17];
	ld.global.f32 	%f22, [%rd15];
	fma.rn.f32 	%f23, %f22, %f21, %f20;
	add.s32 	%r46, %r60, 3;
	add.s32 	%r47, %r46, %r8;
	mul.wide.u32 	%rd18, %r47, 4;
	add.s64 	%rd19, %rd2, %rd18;
	add.s32 	%r48, %r46, %r9;
	mul.wide.u32 	%rd20, %r48, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.f32 	%f24, [%rd21];
	ld.global.f32 	%f25, [%rd19];
	fma.rn.f32 	%f39, %f25, %f24, %f23;
	add.s32 	%r60, %r60, 4;
	add.s32 	%r49, %r4, %r60;
	setp.ne.s32 	%p5, %r49, 0;
	@%p5 bra 	$L__BB2_6;

$L__BB2_7:
	setp.eq.s32 	%p6, %r3, 0;
	@%p6 bra 	$L__BB2_11;

	setp.eq.s32 	%p7, %r3, 1;
	add.s32 	%r50, %r60, %r8;
	mul.wide.u32 	%rd22, %r50, 4;
	add.s64 	%rd23, %rd2, %rd22;
	add.s32 	%r51, %r60, %r9;
	mul.wide.u32 	%rd24, %r51, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.f32 	%f26, [%rd25];
	ld.global.f32 	%f27, [%rd23];
	fma.rn.f32 	%f39, %f27, %f26, %f39;
	@%p7 bra 	$L__BB2_11;

	setp.eq.s32 	%p8, %r3, 2;
	add.s32 	%r52, %r60, 1;
	add.s32 	%r53, %r52, %r8;
	mul.wide.u32 	%rd26, %r53, 4;
	add.s64 	%rd27, %rd2, %rd26;
	add.s32 	%r54, %r52, %r9;
	mul.wide.u32 	%rd28, %r54, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.f32 	%f28, [%rd29];
	ld.global.f32 	%f29, [%rd27];
	fma.rn.f32 	%f39, %f29, %f28, %f39;
	@%p8 bra 	$L__BB2_11;

	add.s32 	%r55, %r60, 2;
	add.s32 	%r56, %r55, %r8;
	mul.wide.u32 	%rd30, %r56, 4;
	add.s64 	%rd31, %rd2, %rd30;
	add.s32 	%r57, %r55, %r9;
	mul.wide.u32 	%rd32, %r57, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f32 	%f30, [%rd33];
	ld.global.f32 	%f31, [%rd31];
	fma.rn.f32 	%f39, %f31, %f30, %f39;

$L__BB2_11:
	add.s32 	%r58, %r58, 1;
	setp.lt.u32 	%p9, %r58, %r20;
	@%p9 bra 	$L__BB2_4;

$L__BB2_12:
	cvta.to.global.u64 	%rd34, %rd3;
	mul.wide.s32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.f32 	%f32, [%rd36];
	add.f32 	%f33, %f39, %f32;
	st.global.f32 	[%rd36], %f33;

$L__BB2_13:
	ret;

}
	// .globl	backward_bias
.visible .entry backward_bias(
	.param .u64 backward_bias_param_0,
	.param .u64 backward_bias_param_1,
	.param .u32 backward_bias_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<6>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd1, [backward_bias_param_0];
	ld.param.u64 	%rd2, [backward_bias_param_1];
	ld.param.u32 	%r2, [backward_bias_param_2];
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	setp.ge.u32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB3_2;

	cvta.to.global.u64 	%rd3, %rd1;
	mul.wide.s32 	%rd4, %r1, 4;
	add.s64 	%rd5, %rd3, %rd4;
	cvta.to.global.u64 	%rd6, %rd2;
	add.s64 	%rd7, %rd6, %rd4;
	ld.global.f32 	%f1, [%rd7];
	ld.global.f32 	%f2, [%rd5];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd7], %f3;

$L__BB3_2:
	ret;

}

