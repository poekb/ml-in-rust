//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36037853
// Cuda compilation tools, release 12.9, V12.9.86
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_52
.address_size 64

	// .globl	forward

.visible .entry forward(
	.param .u64 forward_param_0,
	.param .u64 forward_param_1,
	.param .u64 forward_param_2,
	.param .u64 forward_param_3,
	.param .u32 forward_param_4,
	.param .u32 forward_param_5,
	.param .u32 forward_param_6,
	.param .u32 forward_param_7,
	.param .u32 forward_param_8,
	.param .u32 forward_param_9,
	.param .u32 forward_param_10,
	.param .u32 forward_param_11
)
{
	.reg .pred 	%p<13>;
	.reg .f32 	%f<43>;
	.reg .b32 	%r<65>;
	.reg .b64 	%rd<41>;


	ld.param.u64 	%rd5, [forward_param_0];
	ld.param.u64 	%rd3, [forward_param_1];
	ld.param.u64 	%rd6, [forward_param_2];
	ld.param.u64 	%rd4, [forward_param_3];
	ld.param.u32 	%r21, [forward_param_4];
	ld.param.u32 	%r22, [forward_param_5];
	ld.param.u32 	%r23, [forward_param_6];
	ld.param.u32 	%r24, [forward_param_7];
	ld.param.u32 	%r25, [forward_param_8];
	ld.param.u32 	%r27, [forward_param_9];
	ld.param.u32 	%r26, [forward_param_10];
	ld.param.u32 	%r28, [forward_param_11];
	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd5;
	mov.u32 	%r29, %ntid.x;
	mov.u32 	%r30, %ctaid.x;
	mov.u32 	%r31, %tid.x;
	mad.lo.s32 	%r1, %r30, %r29, %r31;
	mul.lo.s32 	%r2, %r28, %r26;
	mul.lo.s32 	%r32, %r2, %r27;
	setp.ge.u32 	%p1, %r1, %r32;
	mov.f32 	%f41, 0f00000000;
	@%p1 bra 	$L__BB0_15;

	div.u32 	%r3, %r1, %r2;
	setp.eq.s32 	%p2, %r21, 0;
	@%p2 bra 	$L__BB0_14;

	setp.eq.s32 	%p3, %r25, 0;
	setp.eq.s32 	%p4, %r24, 0;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	$L__BB0_14;

	add.s32 	%r4, %r24, -1;
	and.b32  	%r5, %r24, 3;
	sub.s32 	%r6, %r5, %r24;
	rem.u32 	%r34, %r1, %r2;
	div.u32 	%r7, %r34, %r26;
	rem.u32 	%r8, %r1, %r26;
	mul.lo.s32 	%r9, %r3, %r21;
	mov.f32 	%f41, 0f00000000;
	mov.u32 	%r33, 0;
	mov.u32 	%r61, %r33;

$L__BB0_4:
	mad.lo.s32 	%r11, %r61, %r23, %r7;
	add.s32 	%r36, %r61, %r9;
	mul.lo.s32 	%r12, %r36, %r25;
	mov.u32 	%r62, %r33;

$L__BB0_5:
	add.s32 	%r38, %r11, %r62;
	mad.lo.s32 	%r14, %r38, %r22, %r8;
	add.s32 	%r39, %r12, %r62;
	mul.lo.s32 	%r15, %r39, %r24;
	setp.lt.u32 	%p6, %r4, 3;
	mov.u32 	%r64, 0;
	@%p6 bra 	$L__BB0_8;

	mov.u32 	%r64, 0;

$L__BB0_7:
	add.s32 	%r41, %r14, %r64;
	mul.wide.u32 	%rd7, %r41, 4;
	add.s64 	%rd8, %rd2, %rd7;
	add.s32 	%r42, %r64, %r15;
	mul.wide.u32 	%rd9, %r42, 4;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.f32 	%f16, [%rd10];
	ld.global.f32 	%f17, [%rd8];
	fma.rn.f32 	%f18, %f17, %f16, %f41;
	add.s32 	%r43, %r64, 1;
	add.s32 	%r44, %r14, %r43;
	mul.wide.u32 	%rd11, %r44, 4;
	add.s64 	%rd12, %rd2, %rd11;
	add.s32 	%r45, %r43, %r15;
	mul.wide.u32 	%rd13, %r45, 4;
	add.s64 	%rd14, %rd1, %rd13;
	ld.global.f32 	%f19, [%rd14];
	ld.global.f32 	%f20, [%rd12];
	fma.rn.f32 	%f21, %f20, %f19, %f18;
	add.s32 	%r46, %r64, 2;
	add.s32 	%r47, %r14, %r46;
	mul.wide.u32 	%rd15, %r47, 4;
	add.s64 	%rd16, %rd2, %rd15;
	add.s32 	%r48, %r46, %r15;
	mul.wide.u32 	%rd17, %r48, 4;
	add.s64 	%rd18, %rd1, %rd17;
	ld.global.f32 	%f22, [%rd18];
	ld.global.f32 	%f23, [%rd16];
	fma.rn.f32 	%f24, %f23, %f22, %f21;
	add.s32 	%r49, %r64, 3;
	add.s32 	%r50, %r14, %r49;
	mul.wide.u32 	%rd19, %r50, 4;
	add.s64 	%rd20, %rd2, %rd19;
	add.s32 	%r51, %r49, %r15;
	mul.wide.u32 	%rd21, %r51, 4;
	add.s64 	%rd22, %rd1, %rd21;
	ld.global.f32 	%f25, [%rd22];
	ld.global.f32 	%f26, [%rd20];
	fma.rn.f32 	%f41, %f26, %f25, %f24;
	add.s32 	%r64, %r64, 4;
	add.s32 	%r52, %r6, %r64;
	setp.ne.s32 	%p7, %r52, 0;
	@%p7 bra 	$L__BB0_7;

$L__BB0_8:
	setp.eq.s32 	%p8, %r5, 0;
	@%p8 bra 	$L__BB0_12;

	setp.eq.s32 	%p9, %r5, 1;
	add.s32 	%r53, %r14, %r64;
	mul.wide.u32 	%rd23, %r53, 4;
	add.s64 	%rd24, %rd2, %rd23;
	add.s32 	%r54, %r64, %r15;
	mul.wide.u32 	%rd25, %r54, 4;
	add.s64 	%rd26, %rd1, %rd25;
	ld.global.f32 	%f27, [%rd26];
	ld.global.f32 	%f28, [%rd24];
	fma.rn.f32 	%f41, %f28, %f27, %f41;
	@%p9 bra 	$L__BB0_12;

	add.s32 	%r55, %r64, 1;
	setp.eq.s32 	%p10, %r5, 2;
	add.s32 	%r56, %r14, %r55;
	mul.wide.u32 	%rd27, %r56, 4;
	add.s64 	%rd28, %rd2, %rd27;
	add.s32 	%r57, %r55, %r15;
	mul.wide.u32 	%rd29, %r57, 4;
	add.s64 	%rd30, %rd1, %rd29;
	ld.global.f32 	%f29, [%rd30];
	ld.global.f32 	%f30, [%rd28];
	fma.rn.f32 	%f41, %f30, %f29, %f41;
	@%p10 bra 	$L__BB0_12;

	add.s32 	%r58, %r64, 2;
	add.s32 	%r59, %r14, %r58;
	mul.wide.u32 	%rd31, %r59, 4;
	add.s64 	%rd32, %rd2, %rd31;
	add.s32 	%r60, %r58, %r15;
	mul.wide.u32 	%rd33, %r60, 4;
	add.s64 	%rd34, %rd1, %rd33;
	ld.global.f32 	%f31, [%rd34];
	ld.global.f32 	%f32, [%rd32];
	fma.rn.f32 	%f41, %f32, %f31, %f41;

$L__BB0_12:
	add.s32 	%r62, %r62, 1;
	setp.lt.u32 	%p11, %r62, %r25;
	@%p11 bra 	$L__BB0_5;

	add.s32 	%r61, %r61, 1;
	setp.lt.u32 	%p12, %r61, %r21;
	@%p12 bra 	$L__BB0_4;

$L__BB0_14:
	cvta.to.global.u64 	%rd35, %rd4;
	mul.wide.s32 	%rd36, %r3, 4;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.f32 	%f33, [%rd37];
	add.f32 	%f34, %f41, %f33;
	cvta.to.global.u64 	%rd38, %rd3;
	mul.wide.s32 	%rd39, %r1, 4;
	add.s64 	%rd40, %rd38, %rd39;
	st.global.f32 	[%rd40], %f34;

$L__BB0_15:
	ret;

}
	// .globl	backward_input
.visible .entry backward_input(
	.param .u64 backward_input_param_0,
	.param .u64 backward_input_param_1,
	.param .u64 backward_input_param_2,
	.param .u32 backward_input_param_3,
	.param .u32 backward_input_param_4,
	.param .u32 backward_input_param_5,
	.param .u32 backward_input_param_6,
	.param .u32 backward_input_param_7,
	.param .u32 backward_input_param_8,
	.param .u32 backward_input_param_9,
	.param .u32 backward_input_param_10
)
{
	.reg .pred 	%p<47>;
	.reg .f32 	%f<55>;
	.reg .b32 	%r<97>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd4, [backward_input_param_0];
	ld.param.u64 	%rd3, [backward_input_param_1];
	ld.param.u64 	%rd5, [backward_input_param_2];
	ld.param.u32 	%r34, [backward_input_param_3];
	ld.param.u32 	%r35, [backward_input_param_4];
	ld.param.u32 	%r36, [backward_input_param_5];
	ld.param.u32 	%r37, [backward_input_param_6];
	ld.param.u32 	%r38, [backward_input_param_7];
	ld.param.u32 	%r39, [backward_input_param_8];
	ld.param.u32 	%r40, [backward_input_param_9];
	ld.param.u32 	%r41, [backward_input_param_10];
	cvta.to.global.u64 	%rd1, %rd5;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r42, %ntid.x;
	mov.u32 	%r43, %ctaid.x;
	mov.u32 	%r44, %tid.x;
	mad.lo.s32 	%r1, %r43, %r42, %r44;
	mul.lo.s32 	%r45, %r35, %r34;
	mul.lo.s32 	%r46, %r45, %r36;
	setp.ge.s32 	%p1, %r1, %r46;
	mov.f32 	%f44, 0f00000000;
	@%p1 bra 	$L__BB1_29;

	rem.u32 	%r2, %r1, %r35;
	setp.eq.s32 	%p2, %r39, 0;
	@%p2 bra 	$L__BB1_28;

	setp.eq.s32 	%p3, %r38, 0;
	@%p3 bra 	$L__BB1_28;

	mul.lo.s32 	%r48, %r36, %r35;
	add.s32 	%r3, %r37, -1;
	and.b32  	%r4, %r37, 3;
	sub.s32 	%r5, %r4, %r37;
	div.u32 	%r6, %r1, %r48;
	mul.lo.s32 	%r49, %r6, %r48;
	sub.s32 	%r50, %r1, %r49;
	div.u32 	%r7, %r50, %r35;
	mov.f32 	%f44, 0f00000000;
	mov.u32 	%r93, 0;

$L__BB1_4:
	setp.eq.s32 	%p4, %r37, 0;
	@%p4 bra 	$L__BB1_27;

	mad.lo.s32 	%r52, %r93, %r34, %r6;
	mul.lo.s32 	%r9, %r52, %r38;
	mul.lo.s32 	%r10, %r93, %r41;
	mov.u32 	%r51, 0;
	mov.u32 	%r94, %r51;

$L__BB1_6:
	not.b32 	%r54, %r94;
	add.s32 	%r55, %r54, %r38;
	sub.s32 	%r12, %r7, %r55;
	add.s32 	%r56, %r12, %r10;
	mul.lo.s32 	%r13, %r56, %r40;
	add.s32 	%r57, %r9, %r55;
	mul.lo.s32 	%r14, %r57, %r37;
	setp.lt.u32 	%p5, %r3, 3;
	mov.u32 	%r96, %r51;
	@%p5 bra 	$L__BB1_17;

	mov.u32 	%r96, 0;

$L__BB1_8:
	not.b32 	%r59, %r96;
	add.s32 	%r16, %r59, %r37;
	sub.s32 	%r17, %r2, %r16;
	or.b32  	%r60, %r17, %r12;
	setp.lt.s32 	%p6, %r60, 0;
	setp.ge.u32 	%p7, %r12, %r41;
	or.pred  	%p8, %p7, %p6;
	setp.ge.u32 	%p9, %r17, %r40;
	or.pred  	%p10, %p9, %p8;
	@%p10 bra 	$L__BB1_10;

	add.s32 	%r61, %r17, %r13;
	mul.wide.u32 	%rd6, %r61, 4;
	add.s64 	%rd7, %rd2, %rd6;
	add.s32 	%r62, %r16, %r14;
	mul.wide.u32 	%rd8, %r62, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.f32 	%f26, [%rd9];
	ld.global.f32 	%f27, [%rd7];
	fma.rn.f32 	%f44, %f27, %f26, %f44;

$L__BB1_10:
	mov.u32 	%r63, -2;
	sub.s32 	%r64, %r63, %r96;
	add.s32 	%r18, %r64, %r37;
	sub.s32 	%r19, %r2, %r18;
	or.b32  	%r65, %r19, %r12;
	setp.lt.s32 	%p11, %r65, 0;
	or.pred  	%p13, %p7, %p11;
	setp.ge.u32 	%p14, %r19, %r40;
	or.pred  	%p15, %p14, %p13;
	@%p15 bra 	$L__BB1_12;

	add.s32 	%r66, %r19, %r13;
	mul.wide.u32 	%rd10, %r66, 4;
	add.s64 	%rd11, %rd2, %rd10;
	add.s32 	%r67, %r18, %r14;
	mul.wide.u32 	%rd12, %r67, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f32 	%f28, [%rd13];
	ld.global.f32 	%f29, [%rd11];
	fma.rn.f32 	%f44, %f29, %f28, %f44;

$L__BB1_12:
	mov.u32 	%r68, -3;
	sub.s32 	%r69, %r68, %r96;
	add.s32 	%r20, %r69, %r37;
	sub.s32 	%r21, %r2, %r20;
	or.b32  	%r70, %r21, %r12;
	setp.lt.s32 	%p16, %r70, 0;
	or.pred  	%p18, %p7, %p16;
	setp.ge.u32 	%p19, %r21, %r40;
	or.pred  	%p20, %p19, %p18;
	@%p20 bra 	$L__BB1_14;

	add.s32 	%r71, %r21, %r13;
	mul.wide.u32 	%rd14, %r71, 4;
	add.s64 	%rd15, %rd2, %rd14;
	add.s32 	%r72, %r20, %r14;
	mul.wide.u32 	%rd16, %r72, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.f32 	%f30, [%rd17];
	ld.global.f32 	%f31, [%rd15];
	fma.rn.f32 	%f44, %f31, %f30, %f44;

$L__BB1_14:
	mov.u32 	%r73, -4;
	sub.s32 	%r74, %r73, %r96;
	add.s32 	%r22, %r74, %r37;
	sub.s32 	%r23, %r2, %r22;
	or.b32  	%r75, %r23, %r12;
	setp.lt.s32 	%p21, %r75, 0;
	or.pred  	%p23, %p7, %p21;
	setp.ge.u32 	%p24, %r23, %r40;
	or.pred  	%p25, %p24, %p23;
	@%p25 bra 	$L__BB1_16;

	add.s32 	%r76, %r23, %r13;
	mul.wide.u32 	%rd18, %r76, 4;
	add.s64 	%rd19, %rd2, %rd18;
	add.s32 	%r77, %r22, %r14;
	mul.wide.u32 	%rd20, %r77, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.f32 	%f32, [%rd21];
	ld.global.f32 	%f33, [%rd19];
	fma.rn.f32 	%f44, %f33, %f32, %f44;

$L__BB1_16:
	add.s32 	%r96, %r96, 4;
	add.s32 	%r78, %r5, %r96;
	setp.ne.s32 	%p26, %r78, 0;
	@%p26 bra 	$L__BB1_8;

$L__BB1_17:
	setp.eq.s32 	%p27, %r4, 0;
	@%p27 bra 	$L__BB1_26;

	setp.ge.u32 	%p28, %r12, %r41;
	not.b32 	%r79, %r96;
	add.s32 	%r26, %r79, %r37;
	sub.s32 	%r27, %r2, %r26;
	or.b32  	%r80, %r27, %r12;
	setp.lt.s32 	%p29, %r80, 0;
	or.pred  	%p30, %p28, %p29;
	setp.ge.u32 	%p31, %r27, %r40;
	or.pred  	%p32, %p31, %p30;
	@%p32 bra 	$L__BB1_20;

	add.s32 	%r81, %r27, %r13;
	mul.wide.u32 	%rd22, %r81, 4;
	add.s64 	%rd23, %rd2, %rd22;
	add.s32 	%r82, %r26, %r14;
	mul.wide.u32 	%rd24, %r82, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.f32 	%f34, [%rd25];
	ld.global.f32 	%f35, [%rd23];
	fma.rn.f32 	%f44, %f35, %f34, %f44;

$L__BB1_20:
	setp.eq.s32 	%p33, %r4, 1;
	@%p33 bra 	$L__BB1_26;

	mov.u32 	%r83, -2;
	sub.s32 	%r84, %r83, %r96;
	add.s32 	%r28, %r84, %r37;
	sub.s32 	%r29, %r2, %r28;
	or.b32  	%r85, %r29, %r12;
	setp.lt.s32 	%p35, %r85, 0;
	or.pred  	%p36, %p28, %p35;
	setp.ge.u32 	%p37, %r29, %r40;
	or.pred  	%p38, %p37, %p36;
	@%p38 bra 	$L__BB1_23;

	add.s32 	%r86, %r29, %r13;
	mul.wide.u32 	%rd26, %r86, 4;
	add.s64 	%rd27, %rd2, %rd26;
	add.s32 	%r87, %r28, %r14;
	mul.wide.u32 	%rd28, %r87, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.f32 	%f36, [%rd29];
	ld.global.f32 	%f37, [%rd27];
	fma.rn.f32 	%f44, %f37, %f36, %f44;

$L__BB1_23:
	setp.eq.s32 	%p39, %r4, 2;
	@%p39 bra 	$L__BB1_26;

	mov.u32 	%r88, -3;
	sub.s32 	%r89, %r88, %r96;
	add.s32 	%r30, %r89, %r37;
	sub.s32 	%r31, %r2, %r30;
	or.b32  	%r90, %r31, %r12;
	setp.lt.s32 	%p41, %r90, 0;
	or.pred  	%p42, %p28, %p41;
	setp.ge.u32 	%p43, %r31, %r40;
	or.pred  	%p44, %p43, %p42;
	@%p44 bra 	$L__BB1_26;

	add.s32 	%r91, %r31, %r13;
	mul.wide.u32 	%rd30, %r91, 4;
	add.s64 	%rd31, %rd2, %rd30;
	add.s32 	%r92, %r30, %r14;
	mul.wide.u32 	%rd32, %r92, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f32 	%f38, [%rd33];
	ld.global.f32 	%f39, [%rd31];
	fma.rn.f32 	%f44, %f39, %f38, %f44;

$L__BB1_26:
	add.s32 	%r94, %r94, 1;
	setp.lt.u32 	%p45, %r94, %r38;
	@%p45 bra 	$L__BB1_6;

$L__BB1_27:
	add.s32 	%r93, %r93, 1;
	setp.lt.u32 	%p46, %r93, %r39;
	@%p46 bra 	$L__BB1_4;

$L__BB1_28:
	cvta.to.global.u64 	%rd34, %rd3;
	mul.wide.s32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	st.global.f32 	[%rd36], %f44;

$L__BB1_29:
	ret;

}
	// .globl	backward_kernel
.visible .entry backward_kernel(
	.param .u64 backward_kernel_param_0,
	.param .u64 backward_kernel_param_1,
	.param .u64 backward_kernel_param_2,
	.param .u32 backward_kernel_param_3,
	.param .u32 backward_kernel_param_4,
	.param .u32 backward_kernel_param_5,
	.param .u32 backward_kernel_param_6,
	.param .u32 backward_kernel_param_7,
	.param .u32 backward_kernel_param_8,
	.param .u32 backward_kernel_param_9,
	.param .u32 backward_kernel_param_10
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<41>;
	.reg .b32 	%r<65>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd4, [backward_kernel_param_0];
	ld.param.u64 	%rd5, [backward_kernel_param_1];
	ld.param.u64 	%rd3, [backward_kernel_param_2];
	ld.param.u32 	%r15, [backward_kernel_param_3];
	ld.param.u32 	%r16, [backward_kernel_param_4];
	ld.param.u32 	%r17, [backward_kernel_param_5];
	ld.param.u32 	%r18, [backward_kernel_param_6];
	ld.param.u32 	%r19, [backward_kernel_param_7];
	ld.param.u32 	%r22, [backward_kernel_param_8];
	ld.param.u32 	%r20, [backward_kernel_param_9];
	ld.param.u32 	%r21, [backward_kernel_param_10];
	cvta.to.global.u64 	%rd1, %rd5;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r23, %ntid.x;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r1, %r24, %r23, %r25;
	mul.lo.s32 	%r26, %r18, %r15;
	mul.lo.s32 	%r27, %r26, %r19;
	mul.lo.s32 	%r28, %r27, %r22;
	setp.ge.s32 	%p1, %r1, %r28;
	mov.f32 	%f39, 0f00000000;
	@%p1 bra 	$L__BB2_13;

	setp.eq.s32 	%p2, %r21, 0;
	@%p2 bra 	$L__BB2_12;

	setp.eq.s32 	%p3, %r20, 0;
	@%p3 bra 	$L__BB2_12;

	mul.lo.s32 	%r30, %r19, %r18;
	add.s32 	%r2, %r20, -1;
	and.b32  	%r3, %r20, 3;
	sub.s32 	%r4, %r3, %r20;
	rem.u32 	%r5, %r1, %r18;
	mul.lo.s32 	%r31, %r30, %r15;
	div.u32 	%r32, %r1, %r31;
	mul.lo.s32 	%r6, %r32, %r21;
	div.u32 	%r33, %r1, %r30;
	mul.lo.s32 	%r34, %r33, %r30;
	sub.s32 	%r35, %r1, %r34;
	div.u32 	%r36, %r35, %r18;
	rem.u32 	%r37, %r33, %r15;
	mad.lo.s32 	%r7, %r37, %r17, %r36;
	mov.f32 	%f39, 0f00000000;
	mov.u32 	%r29, 0;
	mov.u32 	%r62, %r29;

$L__BB2_4:
	add.s32 	%r39, %r7, %r62;
	mad.lo.s32 	%r9, %r39, %r16, %r5;
	add.s32 	%r40, %r62, %r6;
	mul.lo.s32 	%r10, %r40, %r20;
	setp.lt.u32 	%p4, %r2, 3;
	mov.u32 	%r64, %r29;
	@%p4 bra 	$L__BB2_7;

	mov.u32 	%r64, 0;

$L__BB2_6:
	add.s32 	%r42, %r9, %r64;
	mul.wide.u32 	%rd6, %r42, 4;
	add.s64 	%rd7, %rd2, %rd6;
	add.s32 	%r43, %r64, %r10;
	mul.wide.u32 	%rd8, %r43, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.f32 	%f15, [%rd9];
	ld.global.f32 	%f16, [%rd7];
	fma.rn.f32 	%f17, %f16, %f15, %f39;
	add.s32 	%r44, %r64, 1;
	add.s32 	%r45, %r9, %r44;
	mul.wide.u32 	%rd10, %r45, 4;
	add.s64 	%rd11, %rd2, %rd10;
	add.s32 	%r46, %r44, %r10;
	mul.wide.u32 	%rd12, %r46, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f32 	%f18, [%rd13];
	ld.global.f32 	%f19, [%rd11];
	fma.rn.f32 	%f20, %f19, %f18, %f17;
	add.s32 	%r47, %r64, 2;
	add.s32 	%r48, %r9, %r47;
	mul.wide.u32 	%rd14, %r48, 4;
	add.s64 	%rd15, %rd2, %rd14;
	add.s32 	%r49, %r47, %r10;
	mul.wide.u32 	%rd16, %r49, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.f32 	%f21, [%rd17];
	ld.global.f32 	%f22, [%rd15];
	fma.rn.f32 	%f23, %f22, %f21, %f20;
	add.s32 	%r50, %r64, 3;
	add.s32 	%r51, %r9, %r50;
	mul.wide.u32 	%rd18, %r51, 4;
	add.s64 	%rd19, %rd2, %rd18;
	add.s32 	%r52, %r50, %r10;
	mul.wide.u32 	%rd20, %r52, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.f32 	%f24, [%rd21];
	ld.global.f32 	%f25, [%rd19];
	fma.rn.f32 	%f39, %f25, %f24, %f23;
	add.s32 	%r64, %r64, 4;
	add.s32 	%r53, %r4, %r64;
	setp.ne.s32 	%p5, %r53, 0;
	@%p5 bra 	$L__BB2_6;

$L__BB2_7:
	setp.eq.s32 	%p6, %r3, 0;
	@%p6 bra 	$L__BB2_11;

	setp.eq.s32 	%p7, %r3, 1;
	add.s32 	%r54, %r9, %r64;
	mul.wide.u32 	%rd22, %r54, 4;
	add.s64 	%rd23, %rd2, %rd22;
	add.s32 	%r55, %r64, %r10;
	mul.wide.u32 	%rd24, %r55, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.f32 	%f26, [%rd25];
	ld.global.f32 	%f27, [%rd23];
	fma.rn.f32 	%f39, %f27, %f26, %f39;
	@%p7 bra 	$L__BB2_11;

	add.s32 	%r56, %r64, 1;
	setp.eq.s32 	%p8, %r3, 2;
	add.s32 	%r57, %r9, %r56;
	mul.wide.u32 	%rd26, %r57, 4;
	add.s64 	%rd27, %rd2, %rd26;
	add.s32 	%r58, %r56, %r10;
	mul.wide.u32 	%rd28, %r58, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.f32 	%f28, [%rd29];
	ld.global.f32 	%f29, [%rd27];
	fma.rn.f32 	%f39, %f29, %f28, %f39;
	@%p8 bra 	$L__BB2_11;

	add.s32 	%r59, %r64, 2;
	add.s32 	%r60, %r9, %r59;
	mul.wide.u32 	%rd30, %r60, 4;
	add.s64 	%rd31, %rd2, %rd30;
	add.s32 	%r61, %r59, %r10;
	mul.wide.u32 	%rd32, %r61, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.f32 	%f30, [%rd33];
	ld.global.f32 	%f31, [%rd31];
	fma.rn.f32 	%f39, %f31, %f30, %f39;

$L__BB2_11:
	add.s32 	%r62, %r62, 1;
	setp.lt.u32 	%p9, %r62, %r21;
	@%p9 bra 	$L__BB2_4;

$L__BB2_12:
	cvta.to.global.u64 	%rd34, %rd3;
	mul.wide.s32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.f32 	%f32, [%rd36];
	add.f32 	%f33, %f39, %f32;
	st.global.f32 	[%rd36], %f33;

$L__BB2_13:
	ret;

}
	// .globl	backward_bias
.visible .entry backward_bias(
	.param .u64 backward_bias_param_0,
	.param .u64 backward_bias_param_1,
	.param .u32 backward_bias_param_2,
	.param .u32 backward_bias_param_3,
	.param .u32 backward_bias_param_4
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<27>;
	.reg .b32 	%r<35>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd3, [backward_bias_param_0];
	ld.param.u64 	%rd2, [backward_bias_param_1];
	ld.param.u32 	%r19, [backward_bias_param_2];
	ld.param.u32 	%r17, [backward_bias_param_3];
	ld.param.u32 	%r18, [backward_bias_param_4];
	cvta.to.global.u64 	%rd1, %rd3;
	mov.u32 	%r20, %ntid.x;
	mov.u32 	%r21, %ctaid.x;
	mov.u32 	%r22, %tid.x;
	mad.lo.s32 	%r1, %r21, %r20, %r22;
	setp.ge.u32 	%p1, %r1, %r19;
	@%p1 bra 	$L__BB3_9;

	mul.lo.s32 	%r2, %r18, %r17;
	setp.eq.s32 	%p2, %r2, 0;
	mov.f32 	%f26, 0f00000000;
	@%p2 bra 	$L__BB3_8;

	mul.lo.s32 	%r3, %r2, %r1;
	and.b32  	%r34, %r2, 3;
	add.s32 	%r24, %r2, -1;
	setp.lt.u32 	%p3, %r24, 3;
	mov.f32 	%f26, 0f00000000;
	mov.u32 	%r32, 0;
	@%p3 bra 	$L__BB3_5;

	add.s32 	%r30, %r3, 3;
	sub.s32 	%r6, %r34, %r2;
	mov.f32 	%f26, 0f00000000;
	mov.u32 	%r32, 0;

$L__BB3_4:
	add.s32 	%r26, %r30, -3;
	mul.wide.u32 	%rd4, %r26, 4;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.f32 	%f12, [%rd5];
	add.f32 	%f13, %f26, %f12;
	add.s32 	%r27, %r30, -2;
	mul.wide.u32 	%rd6, %r27, 4;
	add.s64 	%rd7, %rd1, %rd6;
	ld.global.f32 	%f14, [%rd7];
	add.f32 	%f15, %f13, %f14;
	add.s32 	%r28, %r30, -1;
	mul.wide.u32 	%rd8, %r28, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.f32 	%f16, [%rd9];
	add.f32 	%f17, %f15, %f16;
	mul.wide.u32 	%rd10, %r30, 4;
	add.s64 	%rd11, %rd1, %rd10;
	ld.global.f32 	%f18, [%rd11];
	add.f32 	%f26, %f17, %f18;
	add.s32 	%r30, %r30, 4;
	add.s32 	%r32, %r32, 4;
	add.s32 	%r29, %r6, %r32;
	setp.ne.s32 	%p4, %r29, 0;
	@%p4 bra 	$L__BB3_4;

$L__BB3_5:
	setp.eq.s32 	%p5, %r34, 0;
	@%p5 bra 	$L__BB3_8;

	add.s32 	%r33, %r32, %r3;

$L__BB3_7:
	.pragma "nounroll";
	mul.wide.u32 	%rd12, %r33, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.f32 	%f19, [%rd13];
	add.f32 	%f26, %f26, %f19;
	add.s32 	%r33, %r33, 1;
	add.s32 	%r34, %r34, -1;
	setp.ne.s32 	%p6, %r34, 0;
	@%p6 bra 	$L__BB3_7;

$L__BB3_8:
	cvta.to.global.u64 	%rd14, %rd2;
	mul.wide.s32 	%rd15, %r1, 4;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.f32 	%f20, [%rd16];
	add.f32 	%f21, %f26, %f20;
	st.global.f32 	[%rd16], %f21;

$L__BB3_9:
	ret;

}

